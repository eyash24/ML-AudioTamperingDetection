{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 661500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 661500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3986, 1.3725, 0.2144,  ..., 0.5458, 0.2104, 0.9773],\n",
       "        [0.8697, 0.5363, 0.0855,  ..., 0.7451, 2.2866, 2.1207],\n",
       "        [1.2065, 0.7355, 0.5751,  ..., 0.6077, 0.1281, 0.1869],\n",
       "        [0.1603, 0.4982, 0.3391,  ..., 0.7292, 0.0472, 0.9970]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = torch.randn(4, input_size)\n",
    "print(xb.shape)\n",
    "xb = xb.abs()\n",
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DV1(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN1DV1, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.c0 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.c1 = nn.MaxPool1d(kernel_size=self.input_size, stride=1)\n",
    "        self.c2 = nn.Flatten()\n",
    "        self.c3 = nn.Linear(64, 128)\n",
    "        self.c4 = nn.Linear(128, 4)\n",
    "        self.c5 = nn.Softmax(dim=1)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.c0(x)\n",
    "        x2 = self.c1(x1)\n",
    "        x3 = self.c2(x2)\n",
    "        x4 = self.c3(x3)\n",
    "        x5 = self.c4(x4)\n",
    "        x6 = self.c5(x5)\n",
    "        return x6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model Testing\n",
    "x = torch.randn(1, 1, input_size).abs()  # Batch=1, Channels=1, Length=1099228\n",
    "model_2 = CNN1DV1(input_size)\n",
    "output = model_2(x)\n",
    "\n",
    "print(output.shape)  # Expected Output: (1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4554, 0.1494, 0.0859, 0.3094]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN1DV1                                  [1, 4]                    --\n",
       "├─Conv1d: 1-1                            [1, 64, 661500]           256\n",
       "├─MaxPool1d: 1-2                         [1, 64, 1]                --\n",
       "├─Flatten: 1-3                           [1, 64]                   --\n",
       "├─Linear: 1-4                            [1, 128]                  8,320\n",
       "├─Linear: 1-5                            [1, 4]                    516\n",
       "├─Softmax: 1-6                           [1, 4]                    --\n",
       "==========================================================================================\n",
       "Total params: 9,092\n",
       "Trainable params: 9,092\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 169.35\n",
       "==========================================================================================\n",
       "Input size (MB): 2.65\n",
       "Forward/backward pass size (MB): 338.69\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 341.37\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, input_size=(1, 1, input_size), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DV2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN1DV2, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.c0_1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.c0_2 = nn.Conv1d(64, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.c0_3 = nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.c0_4 = nn.Conv1d(256, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.c1 = nn.MaxPool1d(kernel_size=self.input_size, stride=1)\n",
    "        self.c2 = nn.Flatten()\n",
    "        self.c3_1 = nn.Linear(64, 128)\n",
    "        self.c3_2 = nn.Linear(128, 128)\n",
    "        self.c3_3 = nn.Linear(128, 128)\n",
    "        self.c4 = nn.Linear(128, 4)\n",
    "        self.c5 = nn.Softmax(dim=1)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1 = self.c0_1(x)\n",
    "        x1_2 = self.c0_2(x1_1)\n",
    "        x1_3 = self.c0_3(x1_2)\n",
    "        x1_4 = self.c0_4(x1_3)\n",
    "        x2 = self.c1(x1_4)\n",
    "        x3 = self.c2(x2)\n",
    "        x4_1 = self.c3_1(x3)\n",
    "        x4_2 = self.c3_2(x4_1)\n",
    "        x4_3 = self.c3_3(x4_2)\n",
    "        x5 = self.c4(x4_3)\n",
    "        x6 = self.c5(x5)\n",
    "        return x6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model Testing\n",
    "input_size = 661500\n",
    "  # Example input size\n",
    "x = torch.randn(1, 1, input_size).abs()  # Batch=1, Channels=1, Length=1099228\n",
    "model_2 = CNN1DV2(input_size)\n",
    "output = model_2(x)\n",
    "\n",
    "print(output.shape)  # Expected Output: (1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2519, 0.2314, 0.2377, 0.2791]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN1DV2                                  [1, 4]                    --\n",
       "├─Conv1d: 1-1                            [1, 64, 661500]           256\n",
       "├─Conv1d: 1-2                            [1, 256, 661500]          49,408\n",
       "├─Conv1d: 1-3                            [1, 256, 661500]          196,864\n",
       "├─Conv1d: 1-4                            [1, 64, 661500]           49,216\n",
       "├─MaxPool1d: 1-5                         [1, 64, 1]                --\n",
       "├─Flatten: 1-6                           [1, 64]                   --\n",
       "├─Linear: 1-7                            [1, 128]                  8,320\n",
       "├─Linear: 1-8                            [1, 128]                  16,512\n",
       "├─Linear: 1-9                            [1, 128]                  16,512\n",
       "├─Linear: 1-10                           [1, 4]                    516\n",
       "├─Softmax: 1-11                          [1, 4]                    --\n",
       "==========================================================================================\n",
       "Total params: 337,604\n",
       "Trainable params: 337,604\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 195.63\n",
       "==========================================================================================\n",
       "Input size (MB): 2.65\n",
       "Forward/backward pass size (MB): 3386.88\n",
       "Params size (MB): 1.35\n",
       "Estimated Total Size (MB): 3390.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, input_size=(1, 1, input_size), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 661500])\n",
      "torch.Size([1, 64, 661500])\n",
      "torch.Size([1, 256, 661500])\n",
      "torch.Size([1, 256, 661500])\n",
      "torch.Size([1, 256, 661500])\n",
      "torch.Size([1, 64, 661500])\n",
      "torch.Size([1, 64, 1])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "tensor([[0.2330, 0.3722, 0.2273, 0.1675]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "\n",
    "c0_1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "c0_2 = nn.Conv1d(64, 256, kernel_size=3, stride=1, padding=1)\n",
    "c0_3 = nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "c0_4 = nn.Conv1d(256, 64, kernel_size=3, stride=1, padding=1)\n",
    "c1 = nn.MaxPool1d(kernel_size=input_size, stride=1)\n",
    "c2 = nn.Flatten()\n",
    "c3 = nn.Linear(64, 128)\n",
    "c4 = nn.Linear(128, 4)\n",
    "c5 = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "x = torch.randn(1,1,input_size)\n",
    "print(x.shape)\n",
    "x = x.abs()\n",
    "\n",
    "x1_1 = c0_1(x)\n",
    "x1_2 = c0_2(x1_1)\n",
    "x1_3 = c0_3(x1_2)\n",
    "x1_4 = c0_4(x1_3)\n",
    "x2 = c1(x1_4)\n",
    "x3 = c2(x2)\n",
    "x4 = c3(x3)\n",
    "x5 = c4(x4)\n",
    "x6 = c5(x5)\n",
    "\n",
    "outputs = [x1_1,x1_2,x1_3,x1_3,x1_4, x2, x3, x4, x5, x6]\n",
    "for out in outputs:\n",
    "    print(out.shape)\n",
    "print(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2330, 0.3722, 0.2273, 0.1675]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DV3(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN1DV3, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.c1 = nn.Sequential(\n",
    "           nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "           nn.Conv1d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.c3 = nn.Sequential(\n",
    "           nn.Conv1d(256,256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.c4 = nn.Sequential(\n",
    "           nn.Conv1d(256, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.c5 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=self.input_size, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )     \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.c1(x)\n",
    "        x2 = self.c2(x1)\n",
    "        x3 = self.c3(x2)\n",
    "        x4 = self.c4(x3)\n",
    "        x5 = self.c5(x4)\n",
    "        return x5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model Testing\n",
    "input_size = 661500\n",
    "  # Example input size\n",
    "x = torch.randn(4, 1, input_size).abs()  # Batch=1, Channels=1, Length=1099228\n",
    "model_2 = CNN1DV3(input_size)\n",
    "output = model_2(x)\n",
    "\n",
    "print(output.shape)  # Expected Output: (1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3362, 0.1064, 0.2470, 0.3103],\n",
       "        [0.3454, 0.0966, 0.2300, 0.3280],\n",
       "        [0.3422, 0.0978, 0.2478, 0.3122],\n",
       "        [0.3478, 0.1026, 0.2363, 0.3133]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN1DV3                                  [1, 4]                    --\n",
       "├─Sequential: 1-1                        [1, 64, 661500]           --\n",
       "│    └─Conv1d: 2-1                       [1, 64, 661500]           256\n",
       "│    └─BatchNorm1d: 2-2                  [1, 64, 661500]           128\n",
       "│    └─ReLU: 2-3                         [1, 64, 661500]           --\n",
       "├─Sequential: 1-2                        [1, 256, 661500]          --\n",
       "│    └─Conv1d: 2-4                       [1, 256, 661500]          49,408\n",
       "│    └─BatchNorm1d: 2-5                  [1, 256, 661500]          512\n",
       "│    └─ReLU: 2-6                         [1, 256, 661500]          --\n",
       "├─Sequential: 1-3                        [1, 256, 661500]          --\n",
       "│    └─Conv1d: 2-7                       [1, 256, 661500]          196,864\n",
       "│    └─BatchNorm1d: 2-8                  [1, 256, 661500]          512\n",
       "│    └─ReLU: 2-9                         [1, 256, 661500]          --\n",
       "├─Sequential: 1-4                        [1, 64, 661500]           --\n",
       "│    └─Conv1d: 2-10                      [1, 64, 661500]           49,216\n",
       "│    └─BatchNorm1d: 2-11                 [1, 64, 661500]           128\n",
       "│    └─ReLU: 2-12                        [1, 64, 661500]           --\n",
       "├─Sequential: 1-5                        [1, 4]                    --\n",
       "│    └─MaxPool1d: 2-13                   [1, 64, 1]                --\n",
       "│    └─Flatten: 2-14                     [1, 64]                   --\n",
       "│    └─Linear: 2-15                      [1, 128]                  8,320\n",
       "│    └─Linear: 2-16                      [1, 128]                  16,512\n",
       "│    └─Linear: 2-17                      [1, 128]                  16,512\n",
       "│    └─Linear: 2-18                      [1, 4]                    516\n",
       "│    └─Softmax: 2-19                     [1, 4]                    --\n",
       "==========================================================================================\n",
       "Total params: 338,884\n",
       "Trainable params: 338,884\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 195.63\n",
       "==========================================================================================\n",
       "Input size (MB): 2.65\n",
       "Forward/backward pass size (MB): 6773.76\n",
       "Params size (MB): 1.36\n",
       "Estimated Total Size (MB): 6777.76\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, input_size=(1, 1, input_size), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENFCNNModel(nn.Module):\n",
    "    \"\"\"CNN model for audio tampering detection based on ENF features\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ENFCNNModel, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(2), \n",
    "            \n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4, 128),  # Assuming we have at least 32 frames\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ENFCNNModel                              [16, 1]                   --\n",
       "├─Sequential: 1-1                        [16, 64, 4]               --\n",
       "│    └─Conv1d: 2-1                       [16, 16, 4]               64\n",
       "│    └─ReLU: 2-2                         [16, 16, 4]               --\n",
       "│    └─Conv1d: 2-3                       [16, 32, 4]               1,568\n",
       "│    └─ReLU: 2-4                         [16, 32, 4]               --\n",
       "│    └─Conv1d: 2-5                       [16, 64, 4]               6,208\n",
       "│    └─ReLU: 2-6                         [16, 64, 4]               --\n",
       "├─Sequential: 1-2                        [16, 1]                   --\n",
       "│    └─Flatten: 2-7                      [16, 256]                 --\n",
       "│    └─Linear: 2-8                       [16, 128]                 32,896\n",
       "│    └─ReLU: 2-9                         [16, 128]                 --\n",
       "│    └─Dropout: 2-10                     [16, 128]                 --\n",
       "│    └─Linear: 2-11                      [16, 64]                  8,256\n",
       "│    └─ReLU: 2-12                        [16, 64]                  --\n",
       "│    └─Linear: 2-13                      [16, 1]                   65\n",
       "│    └─Sigmoid: 2-14                     [16, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 49,057\n",
       "Trainable params: 49,057\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.16\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.08\n",
       "Params size (MB): 0.20\n",
       "Estimated Total Size (MB): 0.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ENFCNNModel()\n",
    "\n",
    "summary(model = model, input_size=(16,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
